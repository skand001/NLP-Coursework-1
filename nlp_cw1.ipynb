{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Msc Data Science & AI  \n",
    "IS71130A: Natural Language Processing (2023-24)- \n",
    "Assessment 1: Coursework Project (50%) \n",
    "\n",
    "**Asclepius-Synthetic-Clinical-Notes- Summarisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **I. Introducion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **II. Ethics**\n",
    "\n",
    "License: cc-by-nc-sa-4.0\n",
    "\n",
    "Citation Information: \n",
    "@misc{kweon2023publicly,\n",
    "    title={Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes},\n",
    "    author={Sunjun Kweon and Junu Kim and Jiyoun Kim and Sujeong Im and Eunbyeol Cho and Seongsu Bae and Jungwoo Oh and Gyubok Lee and Jong Hak Moon and Seng Chan You and Seungjin Baek and Chang Hoon Han and Yoon Bin Jung and Yohan Jo and Edward Choi},\n",
    "    year={2023},\n",
    "    eprint={2309.00237},\n",
    "    archivePrefix={arXiv},\n",
    "    primaryClass={cs.CL}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **III. Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Data Acquisition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (1.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scispacy in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (0.5.4)\n",
      "Collecting spacy<3.8.0,>=3.7.0\n",
      "  Using cached spacy-3.7.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: numpy in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from scispacy) (1.23.5)\n",
      "Requirement already satisfied: scipy<1.11 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from scispacy) (1.10.1)\n",
      "Requirement already satisfied: pysbd in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from scispacy) (0.3.4)\n",
      "Requirement already satisfied: nmslib>=1.7.3.6 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from scispacy) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from scispacy) (1.2.1)\n",
      "Requirement already satisfied: conllu in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from scispacy) (4.5.3)\n",
      "Requirement already satisfied: joblib in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from scispacy) (1.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from scispacy) (2.28.2)\n",
      "Requirement already satisfied: pybind11<2.6.2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from nmslib>=1.7.3.6->scispacy) (2.6.1)\n",
      "Requirement already satisfied: psutil in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from nmslib>=1.7.3.6->scispacy) (5.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->scispacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->scispacy) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->scispacy) (2023.11.17)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from scikit-learn>=0.20.3->scispacy) (3.1.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.4.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.10.14)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (23.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (4.64.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.10)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (6.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.10.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.7.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.9)\n",
      "Requirement already satisfied: setuptools in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (67.4.0)\n",
      "Collecting thinc<8.3.0,>=8.2.2\n",
      "  Using cached thinc-8.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (937 kB)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.3.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.3.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (4.10.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (8.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->scispacy) (2.1.2)\n",
      "Installing collected packages: thinc, spacy\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.1.12\n",
      "    Uninstalling thinc-8.1.12:\n",
      "      Successfully uninstalled thinc-8.1.12\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.4.4\n",
      "    Uninstalling spacy-3.4.4:\n",
      "      Successfully uninstalled spacy-3.4.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.7.4 which is incompatible.\n",
      "en-core-sci-sm 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.7.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed spacy-3.7.4 thinc-8.2.3\n",
      "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz\n",
      "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz (15.9 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting spacy<3.5.0,>=3.4.1\n",
      "  Using cached spacy-3.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (1.23.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (0.11.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (23.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (2.4.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (0.7.0)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Using cached thinc-8.1.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (935 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (4.64.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (6.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (1.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (1.10.14)\n",
      "Requirement already satisfied: setuptools in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (67.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (2.28.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (2.0.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (3.1.2)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (0.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (4.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (2.1.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (0.7.11)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.1->en-core-sci-sm==0.5.1) (2.1.2)\n",
      "Installing collected packages: thinc, spacy\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.2.3\n",
      "    Uninstalling thinc-8.2.3:\n",
      "      Successfully uninstalled thinc-8.2.3\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.7.4\n",
      "    Uninstalling spacy-3.7.4:\n",
      "      Successfully uninstalled spacy-3.7.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scispacy 0.5.4 requires spacy<3.8.0,>=3.7.0, but you have spacy 3.4.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed spacy-3.4.4 thinc-8.1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install scispacy\n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK is already installed.\n",
      "textblob is already installed.\n",
      "spacy is already installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "\n",
    "# Check if NLTK is already installed\n",
    "if importlib.util.find_spec(\"nltk\") is None:\n",
    "    # NLTK is not installed, so install it\n",
    "    !pip install nltk\n",
    "else:\n",
    "    print(\"NLTK is already installed.\")\n",
    "\n",
    "# Check if textblob is already installed\n",
    "if importlib.util.find_spec(\"textblob\") is None:\n",
    "    # textblob is not installed, so install it\n",
    "    !pip install textblob\n",
    "else:\n",
    "    print(\"textblob is already installed.\")\n",
    "\n",
    "# Check if spacy is already installed\n",
    "if importlib.util.find_spec(\"spacy\") is None:\n",
    "    # spacy is not installed, so install it\n",
    "    !pip install spacy\n",
    "else:\n",
    "    print(\"spacy is already installed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-18 23:35:45.182380: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 23:35:48.314344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 23:35:48.314475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 23:35:48.334344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 23:35:48.334518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 23:35:48.334653: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 23:35:48.334772: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from en-core-web-sm==3.4.1) (3.4.4)\n",
      "Requirement already satisfied: jinja2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.10)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (23.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.14)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.23.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (6.4.0)\n",
      "Requirement already satisfied: setuptools in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (67.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.28.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.11.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2023.11.17)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.11)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-18 23:35:58.382255: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 23:35:59.574523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 23:35:59.574682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 23:35:59.575444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 23:35:59.575548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 23:35:59.575643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-18 23:35:59.575736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "[nltk_data] Downloading package punkt to /home/skanda/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/skanda/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/skanda/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/skanda/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependicies and Requirements\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('synthetic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>note</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Discharge Summary:\\n\\nPatient: 60-year-old mal...</td>\n",
       "      <td>Can you provide a simplified paraphrase of the...</td>\n",
       "      <td>The healthcare team used a gradual approach to...</td>\n",
       "      <td>Paraphrasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Discharge Summary:\\n\\nAdmission Date: [Insert ...</td>\n",
       "      <td>Which coreferences were resolved in the hospit...</td>\n",
       "      <td>The hospital course section resolved the coref...</td>\n",
       "      <td>Coreference Resolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hospital Course Summary:\\n\\nAdmission Date: [I...</td>\n",
       "      <td>What were the key improvements in the patient'...</td>\n",
       "      <td>During the hospital course, the patient's medi...</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Discharge Summary:\\n\\nPatient: 69-year-old mal...</td>\n",
       "      <td>What roles did physical therapists have in the...</td>\n",
       "      <td>Physical therapists were responsible for ensur...</td>\n",
       "      <td>Relation Extraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Discharge Summary:\\n\\nPatient Information:\\n- ...</td>\n",
       "      <td>What manual airway clearance techniques were u...</td>\n",
       "      <td>The discharge summary stated that 1-2 physical...</td>\n",
       "      <td>Relation Extraction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id                                               note  \\\n",
       "0           0  Discharge Summary:\\n\\nPatient: 60-year-old mal...   \n",
       "1           1  Discharge Summary:\\n\\nAdmission Date: [Insert ...   \n",
       "2           2  Hospital Course Summary:\\n\\nAdmission Date: [I...   \n",
       "3           3  Discharge Summary:\\n\\nPatient: 69-year-old mal...   \n",
       "4           4  Discharge Summary:\\n\\nPatient Information:\\n- ...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Can you provide a simplified paraphrase of the...   \n",
       "1  Which coreferences were resolved in the hospit...   \n",
       "2  What were the key improvements in the patient'...   \n",
       "3  What roles did physical therapists have in the...   \n",
       "4  What manual airway clearance techniques were u...   \n",
       "\n",
       "                                              answer                    task  \n",
       "0  The healthcare team used a gradual approach to...            Paraphrasing  \n",
       "1  The hospital course section resolved the coref...  Coreference Resolution  \n",
       "2  During the hospital course, the patient's medi...           Summarization  \n",
       "3  Physical therapists were responsible for ensur...     Relation Extraction  \n",
       "4  The discharge summary stated that 1-2 physical...     Relation Extraction  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data[data['task'] == 'Summarization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19756 entries, 2 to 158107\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   patient_id  19756 non-null  int64 \n",
      " 1   note        19756 non-null  object\n",
      " 2   question    19756 non-null  object\n",
      " 3   answer      19756 non-null  object\n",
      " 4   task        19756 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 926.1+ KB\n"
     ]
    }
   ],
   "source": [
    "filtered_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id    0\n",
       "note          0\n",
       "question      0\n",
       "answer        0\n",
       "task          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>note</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hospital Course Summary:\\n\\nAdmission Date: [I...</td>\n",
       "      <td>What were the key improvements in the patient'...</td>\n",
       "      <td>During the hospital course, the patient's medi...</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Discharge Summary:\\n\\nPatient: 52-year-old mal...</td>\n",
       "      <td>How did the patient's treatment for dysphagia ...</td>\n",
       "      <td>During the patient's hospital stay, treatment ...</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Discharge Summary:\\n\\nPatient Name: [REDACTED]...</td>\n",
       "      <td>Can you provide a summary of the treatment, ho...</td>\n",
       "      <td>The 45-year-old female patient with a history ...</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>DISCHARGE SUMMARY:\\n\\nPatient Name: X\\nMedical...</td>\n",
       "      <td>Based on the given discharge summary, can you ...</td>\n",
       "      <td>The patient with a multifocal invasive mammary...</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>Hospital Course:\\n\\nThe patient is a 78-year-o...</td>\n",
       "      <td>What are the key findings and diagnosis of the...</td>\n",
       "      <td>The key findings of the patient include abnorm...</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158074</th>\n",
       "      <td>166992</td>\n",
       "      <td>Hospital Course:\\n\\nThe patient, a 90-year-old...</td>\n",
       "      <td>What was the diagnosis and treatment course fo...</td>\n",
       "      <td>The 90-year-old male patient was diagnosed wit...</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158077</th>\n",
       "      <td>166995</td>\n",
       "      <td>DISCHARGE SUMMARY\\n\\nPatient Information:\\nNam...</td>\n",
       "      <td>Can you provide a concise summary of the disch...</td>\n",
       "      <td>The patient's chief complaint was extreme fati...</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158080</th>\n",
       "      <td>166999</td>\n",
       "      <td>Hospital Course: \\n\\nJK is a 35-year-old male ...</td>\n",
       "      <td>What was the response to clofarabine and the p...</td>\n",
       "      <td>The 35-year-old male patient with recurrent T-...</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158088</th>\n",
       "      <td>167008</td>\n",
       "      <td>DISCHARGE SUMMARY\\n\\nPatient Name: [redacted]\\...</td>\n",
       "      <td>What was the diagnosis, treatment, and recurre...</td>\n",
       "      <td>Based on the given discharge summary, the pati...</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158107</th>\n",
       "      <td>167027</td>\n",
       "      <td>Discharge Summary:\\n\\nPatient Name: N/A\\nAge: ...</td>\n",
       "      <td>What was the chief complaint, past medical his...</td>\n",
       "      <td>The female patient's chief complaint was sudde...</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19756 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_id                                               note  \\\n",
       "2                2  Hospital Course Summary:\\n\\nAdmission Date: [I...   \n",
       "5                5  Discharge Summary:\\n\\nPatient: 52-year-old mal...   \n",
       "10              11  Discharge Summary:\\n\\nPatient Name: [REDACTED]...   \n",
       "12              13  DISCHARGE SUMMARY:\\n\\nPatient Name: X\\nMedical...   \n",
       "18              20  Hospital Course:\\n\\nThe patient is a 78-year-o...   \n",
       "...            ...                                                ...   \n",
       "158074      166992  Hospital Course:\\n\\nThe patient, a 90-year-old...   \n",
       "158077      166995  DISCHARGE SUMMARY\\n\\nPatient Information:\\nNam...   \n",
       "158080      166999  Hospital Course: \\n\\nJK is a 35-year-old male ...   \n",
       "158088      167008  DISCHARGE SUMMARY\\n\\nPatient Name: [redacted]\\...   \n",
       "158107      167027  Discharge Summary:\\n\\nPatient Name: N/A\\nAge: ...   \n",
       "\n",
       "                                                 question  \\\n",
       "2       What were the key improvements in the patient'...   \n",
       "5       How did the patient's treatment for dysphagia ...   \n",
       "10      Can you provide a summary of the treatment, ho...   \n",
       "12      Based on the given discharge summary, can you ...   \n",
       "18      What are the key findings and diagnosis of the...   \n",
       "...                                                   ...   \n",
       "158074  What was the diagnosis and treatment course fo...   \n",
       "158077  Can you provide a concise summary of the disch...   \n",
       "158080  What was the response to clofarabine and the p...   \n",
       "158088  What was the diagnosis, treatment, and recurre...   \n",
       "158107  What was the chief complaint, past medical his...   \n",
       "\n",
       "                                                   answer           task  \n",
       "2       During the hospital course, the patient's medi...  Summarization  \n",
       "5       During the patient's hospital stay, treatment ...  Summarization  \n",
       "10      The 45-year-old female patient with a history ...  Summarization  \n",
       "12      The patient with a multifocal invasive mammary...  Summarization  \n",
       "18      The key findings of the patient include abnorm...  Summarization  \n",
       "...                                                   ...            ...  \n",
       "158074  The 90-year-old male patient was diagnosed wit...  Summarization  \n",
       "158077  The patient's chief complaint was extreme fati...  Summarization  \n",
       "158080  The 35-year-old male patient with recurrent T-...  Summarization  \n",
       "158088  Based on the given discharge summary, the pati...  Summarization  \n",
       "158107  The female patient's chief complaint was sudde...  Summarization  \n",
       "\n",
       "[19756 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     Hospital Course Summary:\\n\\nAdmission Date: [I...\n",
      "5     Discharge Summary:\\n\\nPatient: 52-year-old mal...\n",
      "10    Discharge Summary:\\n\\nPatient Name: [REDACTED]...\n",
      "12    DISCHARGE SUMMARY:\\n\\nPatient Name: X\\nMedical...\n",
      "18    Hospital Course:\\n\\nThe patient is a 78-year-o...\n",
      "Name: note, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text = filtered_data['note'].head(5)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 Text Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.4 Text Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3935889/3656660417.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['cleaned_note'] = text_preprocessor.clean_text(filtered_data['note'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospital course summary: admission date: discharge date: patient: sex: male age: 57 years admission diagnosis: oxygen desaturation hospital course: the patient was admitted to the icu one week after a positive covid-19 result due to oxygen desaturation. physical therapy was initiated promptly after admission, which helped improve the patient's breathing frequency and oxygen saturation. the patient was guided to achieve a prone position resulting in a significant increase in oxygen saturation from 88% to 96%. the patient continued to receive intensive physical therapy, positioning, and oxygen therapy for the next few days. although there were challenges in achieving the prone position due to the patient's profoundly reduced respiratory capacity and high risk of symptom exacerbation, the medical team succeeded in implementing a safe and individualized approach. after three days with this regime, the patient was transferred to the normal ward, where physical therapists continued his rehabilitation, including walking and strength training. however, the patient's severe instability remained a challenge. nevertheless, after nine days from icu admission, the patient was successfully discharged from the hospital as a pedestrian. discharge condition: at the time of discharge, the patient's medical condition had significantly improved, and he was considered stable enough to be discharged from the hospital. the patient's oxygen saturation had returned to normal limits, and his breathing frequency had decreased significantly. summary: this course summary demonstrates that the patient responded positively to a physical therapy treatment regimen, including positioning, deep-breathing exercises, and walking. although the patient's medical condition was quite severe during the initial icu admission, his rehabilitation resulted in marked improvement, leading to a successful discharge from the hospital.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentences': ['hospital course summary: admission date: discharge date: patient: sex: male age: 57 years admission diagnosis: oxygen desaturation hospital course: the patient was admitted to the icu one week after a positive covid-19 result due to oxygen desaturation.', \"physical therapy was initiated promptly after admission, which helped improve the patient's breathing frequency and oxygen saturation.\", 'the patient was guided to achieve a prone position resulting in a significant increase in oxygen saturation from 88% to 96%.', 'the patient continued to receive intensive physical therapy, positioning, and oxygen therapy for the next few days.', \"although there were challenges in achieving the prone position due to the patient's profoundly reduced respiratory capacity and high risk of symptom exacerbation, the medical team succeeded in implementing a safe and individualized approach.\", 'after three days with this regime, the patient was transferred to the normal ward, where physical therapists continued his rehabilitation, including walking and strength training.', \"however, the patient's severe instability remained a challenge.\", 'nevertheless, after nine days from icu admission, the patient was successfully discharged from the hospital as a pedestrian.', \"discharge condition: at the time of discharge, the patient's medical condition had significantly improved, and he was considered stable enough to be discharged from the hospital.\", \"the patient's oxygen saturation had returned to normal limits, and his breathing frequency had decreased significantly.\", 'summary: this course summary demonstrates that the patient responded positively to a physical therapy treatment regimen, including positioning, deep-breathing exercises, and walking.', \"although the patient's medical condition was quite severe during the initial icu admission, his rehabilitation resulted in marked improvement, leading to a successful discharge from the hospital.\"], 'words': [['hospital', 'course', 'summary', ':', 'admission', 'date', ':', 'discharge', 'date', ':', 'patient', ':', 'sex', ':', 'male', 'age', ':', '57', 'years', 'admission', 'diagnosis', ':', 'oxygen', 'desaturation', 'hospital', 'course', ':', 'the', 'patient', 'was', 'admitted', 'to', 'the', 'icu', 'one', 'week', 'after', 'a', 'positive', 'covid-19', 'result', 'due', 'to', 'oxygen', 'desaturation', '.'], ['physical', 'therapy', 'was', 'initiated', 'promptly', 'after', 'admission', ',', 'which', 'helped', 'improve', 'the', 'patient', \"'s\", 'breathing', 'frequency', 'and', 'oxygen', 'saturation', '.'], ['the', 'patient', 'was', 'guided', 'to', 'achieve', 'a', 'prone', 'position', 'resulting', 'in', 'a', 'significant', 'increase', 'in', 'oxygen', 'saturation', 'from', '88', '%', 'to', '96', '%', '.'], ['the', 'patient', 'continued', 'to', 'receive', 'intensive', 'physical', 'therapy', ',', 'positioning', ',', 'and', 'oxygen', 'therapy', 'for', 'the', 'next', 'few', 'days', '.'], ['although', 'there', 'were', 'challenges', 'in', 'achieving', 'the', 'prone', 'position', 'due', 'to', 'the', 'patient', \"'s\", 'profoundly', 'reduced', 'respiratory', 'capacity', 'and', 'high', 'risk', 'of', 'symptom', 'exacerbation', ',', 'the', 'medical', 'team', 'succeeded', 'in', 'implementing', 'a', 'safe', 'and', 'individualized', 'approach', '.'], ['after', 'three', 'days', 'with', 'this', 'regime', ',', 'the', 'patient', 'was', 'transferred', 'to', 'the', 'normal', 'ward', ',', 'where', 'physical', 'therapists', 'continued', 'his', 'rehabilitation', ',', 'including', 'walking', 'and', 'strength', 'training', '.'], ['however', ',', 'the', 'patient', \"'s\", 'severe', 'instability', 'remained', 'a', 'challenge', '.'], ['nevertheless', ',', 'after', 'nine', 'days', 'from', 'icu', 'admission', ',', 'the', 'patient', 'was', 'successfully', 'discharged', 'from', 'the', 'hospital', 'as', 'a', 'pedestrian', '.'], ['discharge', 'condition', ':', 'at', 'the', 'time', 'of', 'discharge', ',', 'the', 'patient', \"'s\", 'medical', 'condition', 'had', 'significantly', 'improved', ',', 'and', 'he', 'was', 'considered', 'stable', 'enough', 'to', 'be', 'discharged', 'from', 'the', 'hospital', '.'], ['the', 'patient', \"'s\", 'oxygen', 'saturation', 'had', 'returned', 'to', 'normal', 'limits', ',', 'and', 'his', 'breathing', 'frequency', 'had', 'decreased', 'significantly', '.'], ['summary', ':', 'this', 'course', 'summary', 'demonstrates', 'that', 'the', 'patient', 'responded', 'positively', 'to', 'a', 'physical', 'therapy', 'treatment', 'regimen', ',', 'including', 'positioning', ',', 'deep-breathing', 'exercises', ',', 'and', 'walking', '.'], ['although', 'the', 'patient', \"'s\", 'medical', 'condition', 'was', 'quite', 'severe', 'during', 'the', 'initial', 'icu', 'admission', ',', 'his', 'rehabilitation', 'resulted', 'in', 'marked', 'improvement', ',', 'leading', 'to', 'a', 'successful', 'discharge', 'from', 'the', 'hospital', '.']], 'stemmed_words': [['hospit', 'cours', 'summari', ':', 'admiss', 'date', ':', 'discharg', 'date', ':', 'patient', ':', 'sex', ':', 'male', 'age', ':', '57', 'year', 'admiss', 'diagnosi', ':', 'oxygen', 'desatur', 'hospit', 'cours', ':', 'the', 'patient', 'wa', 'admit', 'to', 'the', 'icu', 'one', 'week', 'after', 'a', 'posit', 'covid-19', 'result', 'due', 'to', 'oxygen', 'desatur', '.'], ['physic', 'therapi', 'wa', 'initi', 'promptli', 'after', 'admiss', ',', 'which', 'help', 'improv', 'the', 'patient', \"'s\", 'breath', 'frequenc', 'and', 'oxygen', 'satur', '.'], ['the', 'patient', 'wa', 'guid', 'to', 'achiev', 'a', 'prone', 'posit', 'result', 'in', 'a', 'signific', 'increas', 'in', 'oxygen', 'satur', 'from', '88', '%', 'to', '96', '%', '.'], ['the', 'patient', 'continu', 'to', 'receiv', 'intens', 'physic', 'therapi', ',', 'posit', ',', 'and', 'oxygen', 'therapi', 'for', 'the', 'next', 'few', 'day', '.'], ['although', 'there', 'were', 'challeng', 'in', 'achiev', 'the', 'prone', 'posit', 'due', 'to', 'the', 'patient', \"'s\", 'profoundli', 'reduc', 'respiratori', 'capac', 'and', 'high', 'risk', 'of', 'symptom', 'exacerb', ',', 'the', 'medic', 'team', 'succeed', 'in', 'implement', 'a', 'safe', 'and', 'individu', 'approach', '.'], ['after', 'three', 'day', 'with', 'thi', 'regim', ',', 'the', 'patient', 'wa', 'transfer', 'to', 'the', 'normal', 'ward', ',', 'where', 'physic', 'therapist', 'continu', 'hi', 'rehabilit', ',', 'includ', 'walk', 'and', 'strength', 'train', '.'], ['howev', ',', 'the', 'patient', \"'s\", 'sever', 'instabl', 'remain', 'a', 'challeng', '.'], ['nevertheless', ',', 'after', 'nine', 'day', 'from', 'icu', 'admiss', ',', 'the', 'patient', 'wa', 'success', 'discharg', 'from', 'the', 'hospit', 'as', 'a', 'pedestrian', '.'], ['discharg', 'condit', ':', 'at', 'the', 'time', 'of', 'discharg', ',', 'the', 'patient', \"'s\", 'medic', 'condit', 'had', 'significantli', 'improv', ',', 'and', 'he', 'wa', 'consid', 'stabl', 'enough', 'to', 'be', 'discharg', 'from', 'the', 'hospit', '.'], ['the', 'patient', \"'s\", 'oxygen', 'satur', 'had', 'return', 'to', 'normal', 'limit', ',', 'and', 'hi', 'breath', 'frequenc', 'had', 'decreas', 'significantli', '.'], ['summari', ':', 'thi', 'cours', 'summari', 'demonstr', 'that', 'the', 'patient', 'respond', 'posit', 'to', 'a', 'physic', 'therapi', 'treatment', 'regimen', ',', 'includ', 'posit', ',', 'deep-breath', 'exercis', ',', 'and', 'walk', '.'], ['although', 'the', 'patient', \"'s\", 'medic', 'condit', 'wa', 'quit', 'sever', 'dure', 'the', 'initi', 'icu', 'admiss', ',', 'hi', 'rehabilit', 'result', 'in', 'mark', 'improv', ',', 'lead', 'to', 'a', 'success', 'discharg', 'from', 'the', 'hospit', '.']], 'lemmatized_words': [['hospital', 'course', 'summary', ':', 'admission', 'date', ':', 'discharge', 'date', ':', 'patient', ':', 'sex', ':', 'male', 'age', ':', '57', 'year', 'admission', 'diagnosis', ':', 'oxygen', 'desaturation', 'hospital', 'course', ':', 'the', 'patient', 'wa', 'admitted', 'to', 'the', 'icu', 'one', 'week', 'after', 'a', 'positive', 'covid-19', 'result', 'due', 'to', 'oxygen', 'desaturation', '.'], ['physical', 'therapy', 'wa', 'initiated', 'promptly', 'after', 'admission', ',', 'which', 'helped', 'improve', 'the', 'patient', \"'s\", 'breathing', 'frequency', 'and', 'oxygen', 'saturation', '.'], ['the', 'patient', 'wa', 'guided', 'to', 'achieve', 'a', 'prone', 'position', 'resulting', 'in', 'a', 'significant', 'increase', 'in', 'oxygen', 'saturation', 'from', '88', '%', 'to', '96', '%', '.'], ['the', 'patient', 'continued', 'to', 'receive', 'intensive', 'physical', 'therapy', ',', 'positioning', ',', 'and', 'oxygen', 'therapy', 'for', 'the', 'next', 'few', 'day', '.'], ['although', 'there', 'were', 'challenge', 'in', 'achieving', 'the', 'prone', 'position', 'due', 'to', 'the', 'patient', \"'s\", 'profoundly', 'reduced', 'respiratory', 'capacity', 'and', 'high', 'risk', 'of', 'symptom', 'exacerbation', ',', 'the', 'medical', 'team', 'succeeded', 'in', 'implementing', 'a', 'safe', 'and', 'individualized', 'approach', '.'], ['after', 'three', 'day', 'with', 'this', 'regime', ',', 'the', 'patient', 'wa', 'transferred', 'to', 'the', 'normal', 'ward', ',', 'where', 'physical', 'therapist', 'continued', 'his', 'rehabilitation', ',', 'including', 'walking', 'and', 'strength', 'training', '.'], ['however', ',', 'the', 'patient', \"'s\", 'severe', 'instability', 'remained', 'a', 'challenge', '.'], ['nevertheless', ',', 'after', 'nine', 'day', 'from', 'icu', 'admission', ',', 'the', 'patient', 'wa', 'successfully', 'discharged', 'from', 'the', 'hospital', 'a', 'a', 'pedestrian', '.'], ['discharge', 'condition', ':', 'at', 'the', 'time', 'of', 'discharge', ',', 'the', 'patient', \"'s\", 'medical', 'condition', 'had', 'significantly', 'improved', ',', 'and', 'he', 'wa', 'considered', 'stable', 'enough', 'to', 'be', 'discharged', 'from', 'the', 'hospital', '.'], ['the', 'patient', \"'s\", 'oxygen', 'saturation', 'had', 'returned', 'to', 'normal', 'limit', ',', 'and', 'his', 'breathing', 'frequency', 'had', 'decreased', 'significantly', '.'], ['summary', ':', 'this', 'course', 'summary', 'demonstrates', 'that', 'the', 'patient', 'responded', 'positively', 'to', 'a', 'physical', 'therapy', 'treatment', 'regimen', ',', 'including', 'positioning', ',', 'deep-breathing', 'exercise', ',', 'and', 'walking', '.'], ['although', 'the', 'patient', \"'s\", 'medical', 'condition', 'wa', 'quite', 'severe', 'during', 'the', 'initial', 'icu', 'admission', ',', 'his', 'rehabilitation', 'resulted', 'in', 'marked', 'improvement', ',', 'leading', 'to', 'a', 'successful', 'discharge', 'from', 'the', 'hospital', '.']], 'filtered_sentences': [['hospital', 'course', 'summary', ':', 'admission', 'date', ':', 'discharge', 'date', ':', 'patient', ':', 'sex', ':', 'male', 'age', ':', '57', 'years', 'admission', 'diagnosis', ':', 'oxygen', 'desaturation', 'hospital', 'course', ':', 'patient', 'admitted', 'icu', 'one', 'week', 'positive', 'covid-19', 'result', 'due', 'oxygen', 'desaturation', '.'], ['physical', 'therapy', 'initiated', 'promptly', 'admission', ',', 'helped', 'improve', 'patient', \"'s\", 'breathing', 'frequency', 'oxygen', 'saturation', '.'], ['patient', 'guided', 'achieve', 'prone', 'position', 'resulting', 'significant', 'increase', 'oxygen', 'saturation', '88', '%', '96', '%', '.'], ['patient', 'continued', 'receive', 'intensive', 'physical', 'therapy', ',', 'positioning', ',', 'oxygen', 'therapy', 'next', 'days', '.'], ['although', 'challenges', 'achieving', 'prone', 'position', 'due', 'patient', \"'s\", 'profoundly', 'reduced', 'respiratory', 'capacity', 'high', 'risk', 'symptom', 'exacerbation', ',', 'medical', 'team', 'succeeded', 'implementing', 'safe', 'individualized', 'approach', '.'], ['three', 'days', 'regime', ',', 'patient', 'transferred', 'normal', 'ward', ',', 'physical', 'therapists', 'continued', 'rehabilitation', ',', 'including', 'walking', 'strength', 'training', '.'], ['however', ',', 'patient', \"'s\", 'severe', 'instability', 'remained', 'challenge', '.'], ['nevertheless', ',', 'nine', 'days', 'icu', 'admission', ',', 'patient', 'successfully', 'discharged', 'hospital', 'pedestrian', '.'], ['discharge', 'condition', ':', 'time', 'discharge', ',', 'patient', \"'s\", 'medical', 'condition', 'significantly', 'improved', ',', 'considered', 'stable', 'enough', 'discharged', 'hospital', '.'], ['patient', \"'s\", 'oxygen', 'saturation', 'returned', 'normal', 'limits', ',', 'breathing', 'frequency', 'decreased', 'significantly', '.'], ['summary', ':', 'course', 'summary', 'demonstrates', 'patient', 'responded', 'positively', 'physical', 'therapy', 'treatment', 'regimen', ',', 'including', 'positioning', ',', 'deep-breathing', 'exercises', ',', 'walking', '.'], ['although', 'patient', \"'s\", 'medical', 'condition', 'quite', 'severe', 'initial', 'icu', 'admission', ',', 'rehabilitation', 'resulted', 'marked', 'improvement', ',', 'leading', 'successful', 'discharge', 'hospital', '.']], 'pos_tags': [('hospital', 'NN'), ('course', 'NN'), ('summary', 'NN'), (':', ':'), ('admission', 'NN'), ('date', 'NN'), (':', ':'), ('discharge', 'NN'), ('date', 'NN'), (':', ':'), ('patient', 'NN'), (':', ':'), ('sex', 'NN'), (':', ':'), ('male', 'JJ'), ('age', 'NN'), (':', ':'), ('57', 'CD'), ('years', 'NNS'), ('admission', 'JJ'), ('diagnosis', 'NN'), (':', ':'), ('oxygen', 'NN'), ('desaturation', 'NN'), ('hospital', 'NN'), ('course', 'NN'), (':', ':'), ('patient', 'NN'), ('admitted', 'VBD'), ('icu', 'JJ'), ('one', 'CD'), ('week', 'NN'), ('positive', 'JJ'), ('covid-19', 'JJ'), ('result', 'NN'), ('due', 'JJ'), ('oxygen', 'NN'), ('desaturation', 'NN'), ('.', '.'), ('physical', 'JJ'), ('therapy', 'NN'), ('initiated', 'VBN'), ('promptly', 'RB'), ('admission', 'NN'), (',', ','), ('helped', 'VBD'), ('improve', 'VB'), ('patient', 'NN'), (\"'s\", 'POS'), ('breathing', 'NN'), ('frequency', 'NN'), ('oxygen', 'NN'), ('saturation', 'NN'), ('.', '.'), ('patient', 'NN'), ('guided', 'VBD'), ('achieve', 'RB'), ('prone', 'JJ'), ('position', 'NN'), ('resulting', 'VBG'), ('significant', 'JJ'), ('increase', 'NN'), ('oxygen', 'NN'), ('saturation', 'NN'), ('88', 'CD'), ('%', 'NN'), ('96', 'CD'), ('%', 'NN'), ('.', '.'), ('patient', 'JJ'), ('continued', 'VBD'), ('receive', 'JJ'), ('intensive', 'JJ'), ('physical', 'JJ'), ('therapy', 'NN'), (',', ','), ('positioning', 'NN'), (',', ','), ('oxygen', 'NN'), ('therapy', 'NN'), ('next', 'JJ'), ('days', 'NNS'), ('.', '.'), ('although', 'IN'), ('challenges', 'NNS'), ('achieving', 'VBG'), ('prone', 'NN'), ('position', 'NN'), ('due', 'JJ'), ('patient', 'NN'), (\"'s\", 'POS'), ('profoundly', 'RB'), ('reduced', 'JJ'), ('respiratory', 'NN'), ('capacity', 'NN'), ('high', 'JJ'), ('risk', 'NN'), ('symptom', 'NN'), ('exacerbation', 'NN'), (',', ','), ('medical', 'JJ'), ('team', 'NN'), ('succeeded', 'VBD'), ('implementing', 'VBG'), ('safe', 'JJ'), ('individualized', 'JJ'), ('approach', 'NN'), ('.', '.'), ('three', 'CD'), ('days', 'NNS'), ('regime', 'RB'), (',', ','), ('patient', 'JJ'), ('transferred', 'VBD'), ('normal', 'JJ'), ('ward', 'NN'), (',', ','), ('physical', 'JJ'), ('therapists', 'NNS'), ('continued', 'VBD'), ('rehabilitation', 'NN'), (',', ','), ('including', 'VBG'), ('walking', 'VBG'), ('strength', 'NN'), ('training', 'NN'), ('.', '.'), ('however', 'RB'), (',', ','), ('patient', 'NN'), (\"'s\", 'POS'), ('severe', 'JJ'), ('instability', 'NN'), ('remained', 'VBD'), ('challenge', 'NN'), ('.', '.'), ('nevertheless', 'RB'), (',', ','), ('nine', 'CD'), ('days', 'NNS'), ('icu', 'JJ'), ('admission', 'NN'), (',', ','), ('patient', 'JJ'), ('successfully', 'RB'), ('discharged', 'VBN'), ('hospital', 'NN'), ('pedestrian', 'NN'), ('.', '.'), ('discharge', 'JJ'), ('condition', 'NN'), (':', ':'), ('time', 'NN'), ('discharge', 'NN'), (',', ','), ('patient', 'NN'), (\"'s\", 'POS'), ('medical', 'JJ'), ('condition', 'NN'), ('significantly', 'RB'), ('improved', 'VBN'), (',', ','), ('considered', 'VBN'), ('stable', 'JJ'), ('enough', 'RB'), ('discharged', 'JJ'), ('hospital', 'NN'), ('.', '.'), ('patient', 'NN'), (\"'s\", 'POS'), ('oxygen', 'NN'), ('saturation', 'NN'), ('returned', 'VBD'), ('normal', 'JJ'), ('limits', 'NNS'), (',', ','), ('breathing', 'VBG'), ('frequency', 'NN'), ('decreased', 'VBN'), ('significantly', 'RB'), ('.', '.'), ('summary', 'JJ'), (':', ':'), ('course', 'NN'), ('summary', 'JJ'), ('demonstrates', 'VBZ'), ('patient', 'NN'), ('responded', 'VBD'), ('positively', 'RB'), ('physical', 'JJ'), ('therapy', 'NN'), ('treatment', 'NN'), ('regimen', 'NNS'), (',', ','), ('including', 'VBG'), ('positioning', 'NN'), (',', ','), ('deep-breathing', 'JJ'), ('exercises', 'NNS'), (',', ','), ('walking', 'VBG'), ('.', '.'), ('although', 'IN'), ('patient', 'NN'), (\"'s\", 'POS'), ('medical', 'JJ'), ('condition', 'NN'), ('quite', 'RB'), ('severe', 'JJ'), ('initial', 'JJ'), ('icu', 'NN'), ('admission', 'NN'), (',', ','), ('rehabilitation', 'NN'), ('resulted', 'VBD'), ('marked', 'JJ'), ('improvement', 'NN'), (',', ','), ('leading', 'VBG'), ('successful', 'JJ'), ('discharge', 'NN'), ('hospital', 'NN'), ('.', '.')]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3935889/3656660417.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['preprocessed_text'] = filtered_data['cleaned_note'].apply(text_preprocessor.preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.placeholder_pattern = r'\\[Insert date\\]|\\[Insert Number\\]|\\[Patient\\'s Name\\]|Patient\\'s Name:'\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def clean_text(self, text_series):\n",
    "        \"\"\"\n",
    "        Cleans the input text by performing several preprocessing steps: placeholder removal, case normalization,\n",
    "        and whitespace normalization.\n",
    "\n",
    "        :param text_series: A pandas Series containing the raw text.\n",
    "        :return: A pandas Series containing the cleaned text.\n",
    "        \"\"\"\n",
    "        cleaned_text = text_series.str.replace(self.placeholder_pattern, '', regex=True, case=False)\n",
    "        cleaned_text = cleaned_text.str.lower()\n",
    "        cleaned_text = cleaned_text.str.split().str.join(' ')\n",
    "        return cleaned_text\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocesses the given text by performing several steps: sentence segmentation, word tokenization,\n",
    "        stemming, lemmatization, stop word removal, and part-of-speech tagging.\n",
    "\n",
    "        :param text: The input cleaned text to preprocess.\n",
    "        :return: A dictionary containing various levels of processed text.\n",
    "        \"\"\"\n",
    "        # Initial preprocessing steps\n",
    "        sentences = sent_tokenize(text)\n",
    "        words = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "        # Stemming and Lemmatization\n",
    "        stemmed_words = [[self.stemmer.stem(word) for word in word_list] for word_list in words]\n",
    "        lemmatized_words = [[self.lemmatizer.lemmatize(word) for word in word_list] for word_list in words]\n",
    "\n",
    "        # Stop Word Removal\n",
    "        filtered_sentences = [[word for word in word_list if word not in self.stop_words] for word_list in words]\n",
    "\n",
    "        # Part-of-Speech Tagging (on filtered sentences to mimic real processing flow)\n",
    "        flat_words = [word for sublist in filtered_sentences for word in sublist]\n",
    "        pos_tags = nltk.pos_tag(flat_words)\n",
    "\n",
    "        return {\n",
    "            'sentences': sentences,\n",
    "            'words': words,\n",
    "            'stemmed_words': stemmed_words,\n",
    "            'lemmatized_words': lemmatized_words,\n",
    "            'filtered_sentences': filtered_sentences,\n",
    "            'pos_tags': pos_tags\n",
    "        }\n",
    "\n",
    "# Create an instance of the TextPreprocessor class\n",
    "text_preprocessor = TextPreprocessor()\n",
    "\n",
    "# Clean the notes and add a new column 'cleaned_note' to the DataFrame\n",
    "filtered_data['cleaned_note'] = text_preprocessor.clean_text(filtered_data['note'])\n",
    "\n",
    "# Access the cleaned notes\n",
    "print(filtered_data['cleaned_note'].iloc[0])\n",
    "\n",
    "# Preprocess the cleaned text and add a new column 'preprocessed_text' to the DataFrame\n",
    "filtered_data['preprocessed_text'] = filtered_data['cleaned_note'].apply(text_preprocessor.preprocess_text)\n",
    "\n",
    "# Access and print the preprocessed text for the first row\n",
    "print(filtered_data['preprocessed_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.5 Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the en_core_sci_sm model\n",
    "nlp = spacy.load(\"en_core_sci_sm\")\n",
    "\n",
    "# Add the \"ner\" component to the pipeline\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "def extract_features(text):\n",
    "    \"\"\"\n",
    "    Extracts medical entities and TF-IDF features from the input text.\n",
    "\n",
    "    :param text: The input text to extract features from.\n",
    "    :return: A tuple containing the list of medical entities and the TF-IDF vector.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract medical entities\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.text, ent.label_))\n",
    "\n",
    "    # Compute TF-IDF vector\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_vector = tfidf_vectorizer.fit_transform([text])\n",
    "\n",
    "    return entities, tfidf_vector\n",
    "\n",
    "# Process a sample clinical note\n",
    "# sample_note = filtered_data['cleaned_note'].iloc[0]\n",
    "# entities, tfidf_vector = extract_features(sample_note)\n",
    "\n",
    "# print(\"Medical Entities:\")\n",
    "# print(entities)\n",
    "\n",
    "# print(\"\\nTF-IDF Vector:\")\n",
    "# print(tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def combine_features(text, entities, tfidf_vector):\n",
    "    \"\"\"\n",
    "    Combines the medical entities and TF-IDF features into a single feature vector.\n",
    "\n",
    "    :param text: The input text.\n",
    "    :param entities: The list of medical entities extracted from the text.\n",
    "    :param tfidf_vector: The TF-IDF vector for the text.\n",
    "    :return: A combined feature vector representing both medical entities and TF-IDF features.\n",
    "    \"\"\"\n",
    "    # Extract unique entity labels\n",
    "    unique_labels = set([label for _, label in entities])\n",
    "\n",
    "    # One-hot encode the entity labels\n",
    "    entity_labels = [label for _, label in entities]\n",
    "    one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "    entity_features = one_hot_encoder.fit_transform([[label] for label in entity_labels])\n",
    "\n",
    "    # Sum the entity features along the rows\n",
    "    combined_entity_features = np.sum(entity_features, axis=0, keepdims=True)\n",
    "\n",
    "    # Combine the entity features and TF-IDF vector\n",
    "    combined_features = np.concatenate((combined_entity_features, tfidf_vector.toarray()), axis=1)\n",
    "\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.5 Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def textrank_summarize(text, num_sentences):\n",
    "#     # Load the spaCy English model\n",
    "#     nlp = spacy.load(\"en_core_sci_sm\")\n",
    "\n",
    "#     # Tokenize the text into sentences\n",
    "#     doc = nlp(text)\n",
    "#     sentences = [sent.text.capitalize() for sent in doc.sents]\n",
    "\n",
    "#     # Create a similarity matrix between sentences\n",
    "#     similarity_matrix = nx.Graph()\n",
    "#     for i in range(len(sentences)):\n",
    "#         for j in range(i+1, len(sentences)):\n",
    "#             similarity = nlp(sentences[i]).similarity(nlp(sentences[j]))\n",
    "#             similarity_matrix.add_edge(i, j, weight=similarity)\n",
    "\n",
    "#     # Apply PageRank to compute sentence importance scores\n",
    "#     scores = nx.pagerank(similarity_matrix)\n",
    "\n",
    "#     # Check if there are any scores assigned to the sentences\n",
    "#     if not scores:\n",
    "#         return \"\"  # Return an empty string if no scores are assigned\n",
    "\n",
    "#     # Sort sentences by their importance scores\n",
    "#     ranked_sentences = sorted([(scores[i], sent) for i, sent in enumerate(sentences)], reverse=True)\n",
    "\n",
    "#     # Extract the top-ranked sentences as the summary\n",
    "#     summary = \" \".join([sent for _, sent in ranked_sentences[:num_sentences]])\n",
    "\n",
    "#     return summary\n",
    "\n",
    "# def process_and_summarize(text):\n",
    "#     # Clean the text\n",
    "#     cleaned_text = text_preprocessor.clean_text(pd.Series(text))[0]\n",
    "    \n",
    "#     # Preprocess the text\n",
    "#     preprocessed_text = text_preprocessor.preprocess_text(cleaned_text)\n",
    "    \n",
    "#     # Extract features (if required)\n",
    "#     # entities = extract_named_entities(cleaned_text)\n",
    "    \n",
    "#     # Apply the TextRank summarization model\n",
    "#     summary = textrank_summarize(cleaned_text, num_sentences=3)\n",
    "    \n",
    "#     return summary\n",
    "\n",
    "# # Apply the process_and_summarize function to the 'note' column with a progress bar\n",
    "# tqdm.pandas(desc=\"Summarizing notes\")\n",
    "# filtered_data['summary'] = filtered_data['note'].progress_apply(process_and_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing notes:  13%|█▎        | 2530/19756 [20:57<2:13:21,  2.15it/s]"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def textrank_summarize(text, num_sentences):\n",
    "    # Load the spaCy English model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Tokenize the text into sentences\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.capitalize() for sent in doc.sents]\n",
    "\n",
    "    # Precompute sentence embeddings using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    sentence_embeddings = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Create a similarity matrix between sentences\n",
    "    similarity_matrix = nx.Graph()\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(i+1, len(sentences)):\n",
    "            similarity = sentence_embeddings[i].dot(sentence_embeddings[j].T).toarray()[0][0]\n",
    "            similarity_matrix.add_edge(i, j, weight=similarity)\n",
    "\n",
    "    # Apply PageRank to compute sentence importance scores\n",
    "    scores = nx.pagerank(similarity_matrix)\n",
    "\n",
    "    # Check if there are any scores assigned to the sentences\n",
    "    if not scores:\n",
    "        return \"\"  # Return an empty string if no scores are assigned\n",
    "\n",
    "    # Sort sentences by their importance scores\n",
    "    ranked_sentences = sorted([(scores[i], sent) for i, sent in enumerate(sentences)], reverse=True)\n",
    "\n",
    "    # Extract the top-ranked sentences as the summary\n",
    "    summary = \" \".join([sent for _, sent in ranked_sentences[:num_sentences]])\n",
    "\n",
    "    return summary\n",
    "\n",
    "def process_and_summarize(text):\n",
    "    # Clean the text\n",
    "    cleaned_text = text_preprocessor.clean_text(pd.Series(text))[0]\n",
    "    \n",
    "    # Preprocess the text\n",
    "    preprocessed_text = text_preprocessor.preprocess_text(cleaned_text)\n",
    "    \n",
    "    # Apply the TextRank summarization model\n",
    "    summary = textrank_summarize(cleaned_text, num_sentences=3)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "tqdm.pandas(desc=\"Summarizing notes\")\n",
    "filtered_data['summary'] = filtered_data['note'].progress_apply(process_and_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fuzzy clustering\n",
    "# import numpy as np\n",
    "# from skfuzzy import cmeans, membership\n",
    "\n",
    "# def apply_fuzzy_clustering(combined_features, n_clusters=3, m=2, error=0.005, maxiter=1000):\n",
    "#     \"\"\"\n",
    "#     Applies fuzzy c-means clustering on the combined features.\n",
    "\n",
    "#     :param combined_features: The combined feature vector.\n",
    "#     :param n_clusters: The number of clusters to create (default: 3).\n",
    "#     :param m: The fuzziness parameter (default: 2).\n",
    "#     :param error: The stopping criterion for the fuzzy c-means algorithm (default: 0.005).\n",
    "#     :param maxiter: The maximum number of iterations for the fuzzy c-means algorithm (default: 1000).\n",
    "#     :return: A tuple containing the cluster centers, cluster membership values, and the number of iterations.\n",
    "#     \"\"\"\n",
    "#     # Apply fuzzy c-means clustering\n",
    "#     cntr, u, _, _, _, _, _, _= cmeans(\n",
    "#         combined_features.T, n_clusters, m, error=error, maxiter=maxiter, init=None\n",
    "#     )\n",
    "\n",
    "#     # Calculate the membership values for each sample\n",
    "#     membership_values = np.argmax(u, axis=0)\n",
    "\n",
    "#     return cntr, u, membership_values\n",
    "\n",
    "# # Process a sample clinical note\n",
    "# sample_note = filtered_data['cleaned_note'].iloc[0]\n",
    "# entities, tfidf_vector = extract_features(sample_note)\n",
    "# combined_features = combine_features(sample_note, entities, tfidf_vector)\n",
    "\n",
    "# # Apply fuzzy clustering\n",
    "# n_clusters = 3\n",
    "# cluster_centers, membership_values, membership_labels = apply_fuzzy_clustering(combined_features, n_clusters=n_clusters)\n",
    "\n",
    "# print(f\"Cluster Centers:\\n{cluster_centers}\")\n",
    "# print(f\"\\nMembership Values:\\n{membership_values}\")\n",
    "# print(f\"\\nMembership Labels:\\n{membership_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **BLEU and ROUGE score for NLP Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'summary'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrouge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Rouge\n\u001b[1;32m      3\u001b[0m rouge \u001b[38;5;241m=\u001b[39m Rouge()\n\u001b[0;32m----> 4\u001b[0m scores \u001b[38;5;241m=\u001b[39m rouge\u001b[38;5;241m.\u001b[39mget_scores(\u001b[43mfiltered_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msummary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, filtered_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_note\u001b[39m\u001b[38;5;124m'\u001b[39m], avg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROUGE scores:\u001b[39m\u001b[38;5;124m\"\u001b[39m, scores)\n",
      "File \u001b[0;32m/mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/mnt/data/skanda/mambaforge/envs/gpu/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'summary'"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(filtered_data['summary'], filtered_data['cleaned_note'], avg=True)\n",
    "print(\"ROUGE scores:\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.6 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IV. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
